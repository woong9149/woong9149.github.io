---
title: "[AWS]아마존 웹서비스 기초지식 3"
layout: single
author_profile: true
read_time: true
comments: true
share: true
related: true
categories:
- AWS
- Scale Out
- 아마존웹서비스 기초지식
- TIL
tags:
- AWS
- Scale Out
- 아마존웹서비스 기초지식
- TIL
- Sharding
- Load Balancer
---

#  Scale out의 소개
 적당한 규모가 되기전에는 Scale up으로 할 수 있는 것은 scale up으로 하는것이 좋다.  Scale out은 복잡성이 너무 크고 그 복잡성은 다른 문제들을 야기할 수 있다.   
Scale up을 하다보면 한계에 도달하게되는데(한 대의 컴퓨터에서 그치는 것이 아니라 여러대의 컴퓨터가 서로협력해서 일을하는 것이 필요할 때),   
그때에 scale out이 필요하다.  간단한 해결책이 있으면 간단하게 해결하고, 중/장기적으로 scale out을 하기 위해서 scale up 단계에서 할 수 있는 것 들을 파악해뒀다가 scale out이 필요할때 빠르게 하는 것이 좋은 방법이다.     

> 개발자는 불필요하게 시스템이 복잡해 지는 것을 경계해야 한다.   

# Scale out의 흐름
인스턴스 한 대에 설치되어있는 소프트웨어를 크게 3개로 나눈다.

<img width="642" alt="스크린샷 2020-04-14 오전 8 58 30" src="https://user-images.githubusercontent.com/42554237/79173332-2a380380-7e32-11ea-8364-18e7c885f847.png">   

Web server : nginx, apache 등
middle ware : php, Django, spring 등
DB : mysql, oracle, sql server 등

한 대의 컴퓨터에서 운영되는 Web Server, Middle Ware, Data Base등을 각각의 컴퓨터로 쪼갠다.   

<img width="642" alt="스크린샷 2020-04-14 오전 8 51 14" src="https://user-images.githubusercontent.com/42554237/79173337-2b693080-7e32-11ea-8cee-469e452aec36.png">   

먼저 DB를 Scale Out 해서 사용하다가, Web Server , Middle Ware도 나눈다

<img width="642" alt="스크린샷 2020-04-14 오전 8 52 24" src="https://user-images.githubusercontent.com/42554237/79173336-2ad09a00-7e32-11ea-9133-416da6a59206.png">   

Data base를 다시 master DB(쓰기)와 slave DB(읽기)로 나누고,
 
<img width="642" alt="스크린샷 2020-04-14 오전 8 53 12" src="https://user-images.githubusercontent.com/42554237/79173335-2a380380-7e32-11ea-9224-7e3bc0488238.png">   

slave DB를 다시 나누기도한다.

<img width="642" alt="스크린샷 2020-04-14 오전 9 00 13" src="https://user-images.githubusercontent.com/42554237/79173331-299f6d00-7e32-11ea-8615-90233b85faec.png">   

**샤딩(sharing)**으로 DB를 더 분산시킨다.

<img width="642" alt="스크린샷 2020-04-14 오전 9 00 24" src="https://user-images.githubusercontent.com/42554237/79173330-2906d680-7e32-11ea-9613-b25b08f0bcb7.png">

Middle ware 도 마찬가지로 다른 컴퓨터로 쪼개서 부하를 분산 시킬 수 있다.

<img width="642" alt="스크린샷 2020-04-14 오전 9 06 13" src="https://user-images.githubusercontent.com/42554237/79173328-286e4000-7e32-11ea-94ce-ad7cdc10b6a7.png">

DNS SERVER에서 Web Server의 IP를 사용자에게 알려주는 방식에서

<img width="642" alt="스크린샷 2020-04-14 오전 9 07 28" src="https://user-images.githubusercontent.com/42554237/79173327-27d5a980-7e32-11ea-871a-810b3e48ce6c.png">   

Web server를 다른 컴퓨터로 쪼갠 후 DNS서버의 설정을 바꿔서, 사용자에 따라 서로 다른 web server의 IP를 분배함으로써 부하를 분산시킬 수 있다.

<img width="642" alt="스크린샷 2020-04-14 오전 9 09 12" src="https://user-images.githubusercontent.com/42554237/79173326-273d1300-7e32-11ea-9643-fd6cfde9f5c7.png">   

더 좋은 방법은 **Load Balancer**(부하의 균형을 잡아주는 장치,서비스,시스템)를 두는 것. 

<img width="642" alt="스크린샷 2020-04-14 오전 9 11 44" src="https://user-images.githubusercontent.com/42554237/79173314-1ee4d800-7e32-11ea-9742-e8b33bcf5a92.png">    
로드밸런서가 각 web server의 IP를 가져셔, 사용자의 접속을 분산시키는 것이다. Web server의 장애나 성능상황을 감지해서 부하를 분산시키기도 한다.  Load Balancer가 **부하분산의 핵심요소**이고, AWS에서는 **ELB**(Elastic Load Balancer)라는 서비스가 있다.